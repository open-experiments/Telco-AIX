{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Receiver Training for 5G PUSCH\n",
    "\n",
    "**Objective**: Train a deep learning model to replace conventional channel estimation + equalization + demapping\n",
    "\n",
    "**Architecture**: ResNet-based neural receiver with attention mechanism\n",
    "\n",
    "**Expected Performance**: 2-3 dB SNR gain at BLER = 10^-2\n",
    "\n",
    "**Training Time**: ~2 hours on RTX 4090\n",
    "\n",
    "---\n",
    "\n",
    "## Neural Receiver Architecture\n",
    "\n",
    "```\n",
    "Input: y (received signal) [batch, num_rx, num_subcarriers, num_symbols, 2]\n",
    "       ‚Üì\n",
    "  Spatial Processing (across RX antennas)\n",
    "       ‚Üì\n",
    "  Frequency-Time Feature Extraction (ResNet blocks)\n",
    "       ‚Üì\n",
    "  Attention Mechanism (focus on data subcarriers)\n",
    "       ‚Üì\n",
    "  LLR Estimation (log-likelihood ratios)\n",
    "       ‚Üì\n",
    "Output: Soft bits [batch, num_bits]\n",
    "```\n",
    "\n",
    "## Key Innovations\n",
    "\n",
    "1. **Joint processing**: No separate channel estimation step\n",
    "2. **SNR-agnostic**: Trained across multiple SNR points\n",
    "3. **Attention**: Learns to focus on reliable subcarriers\n",
    "4. **ResNet backbone**: Deep architecture with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# Configure GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"‚úÖ GPU configured: {gpus}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_path = '/opt/app-root/src/data/pusch_dataset.h5'\n",
    "\n",
    "print(f\"üìÇ Loading dataset: {dataset_path}\")\n",
    "print(f\"   File size: {os.path.getsize(dataset_path) / 1024**3:.2f} GB\")\n",
    "\n",
    "with h5py.File(dataset_path, 'r') as f:\n",
    "    print(\"\\nüìä Dataset Information:\")\n",
    "    print(f\"  y_received: {f['y_received'].shape}\")\n",
    "    print(f\"  h_channel: {f['h_channel'].shape}\")\n",
    "    print(f\"  bits: {f['bits'].shape}\")\n",
    "    print(f\"  snr_db: {f['snr_db'].shape}\")\n",
    "    \n",
    "    # Extract metadata\n",
    "    num_samples = f.attrs['num_samples']\n",
    "    num_rx_antennas = f.attrs['num_rx_antennas']\n",
    "    num_tx_antennas = f.attrs['num_tx_antennas']\n",
    "    num_subcarriers = f.attrs['num_subcarriers']\n",
    "    num_ofdm_symbols = f.attrs['num_ofdm_symbols']\n",
    "    modulation_order = f.attrs['modulation_order']\n",
    "    \n",
    "    print(f\"\\nüìã Metadata:\")\n",
    "    print(f\"  Total samples: {num_samples:,}\")\n",
    "    print(f\"  RX antennas: {num_rx_antennas}\")\n",
    "    print(f\"  Subcarriers: {num_subcarriers}\")\n",
    "    print(f\"  OFDM symbols: {num_ofdm_symbols}\")\n",
    "    print(f\"  Modulation: {modulation_order}-QAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PUSCHDataset:\n",
    "    \"\"\"Efficient data loader for PUSCH training - OPTIMIZED with RAM caching\"\"\"\n",
    "    \n",
    "    def __init__(self, h5_path, batch_size=16, validation_split=0.1):\n",
    "        self.h5_path = h5_path\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        print(\"\\nüì¶ Loading dataset into RAM for fast training...\")\n",
    "        \n",
    "        with h5py.File(h5_path, 'r') as f:\n",
    "            # Load metadata\n",
    "            self.num_samples = f.attrs['num_samples']\n",
    "            self.num_bits = f['bits'].shape[-1]\n",
    "            self.input_shape = f['y_received'].shape[1:]\n",
    "            \n",
    "            # Load ALL data into RAM (faster than HDF5 reads during training)\n",
    "            print(f\"   Loading {self.num_samples:,} samples (~43 GB)...\")\n",
    "            self.y_data = f['y_received'][:]  # Load to RAM\n",
    "            self.bits_data = f['bits'][:]      # Load to RAM\n",
    "            print(f\"   ‚úÖ Data loaded into RAM\")\n",
    "        \n",
    "        # Train/val split\n",
    "        num_val = int(self.num_samples * validation_split)\n",
    "        num_train = self.num_samples - num_val\n",
    "        \n",
    "        # Shuffle indices\n",
    "        np.random.seed(42)\n",
    "        indices = np.random.permutation(self.num_samples)\n",
    "        \n",
    "        self.train_indices = indices[:num_train]\n",
    "        self.val_indices = indices[num_train:]\n",
    "        \n",
    "        print(f\"\\n‚úÖ Dataset loader initialized\")\n",
    "        print(f\"   Training samples: {len(self.train_indices):,}\")\n",
    "        print(f\"   Validation samples: {len(self.val_indices):,}\")\n",
    "        print(f\"   Batch size: {self.batch_size}\")\n",
    "        print(f\"   Input shape: {self.input_shape}\")\n",
    "        print(f\"   Output bits: {self.num_bits}\")\n",
    "    \n",
    "    def _generator(self, indices):\n",
    "        \"\"\"Generator for tf.data.Dataset - reads from RAM (fast!)\"\"\"\n",
    "        num_batches = len(indices) // self.batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            batch_indices = indices[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "            \n",
    "            # Load from RAM (no disk I/O, no sorting needed!)\n",
    "            y = self.y_data[batch_indices]      # Fast RAM access\n",
    "            bits = self.bits_data[batch_indices]  # Fast RAM access\n",
    "            \n",
    "            # Reshape bits to [batch, bits]\n",
    "            bits = bits.reshape(bits.shape[0], -1)\n",
    "            \n",
    "            # Convert complex to real (stack real/imag)\n",
    "            y_real = np.stack([y.real, y.imag], axis=-1).astype(np.float32)\n",
    "            \n",
    "            yield y_real, bits.astype(np.float32)\n",
    "    \n",
    "    def get_dataset(self, training=True):\n",
    "        \"\"\"Get tf.data.Dataset for training or validation\"\"\"\n",
    "        indices = self.train_indices if training else self.val_indices\n",
    "        \n",
    "        # Shuffle training indices each epoch\n",
    "        if training:\n",
    "            np.random.shuffle(indices)\n",
    "        \n",
    "        output_signature = (\n",
    "            tf.TensorSpec(shape=(self.batch_size, *self.input_shape, 2), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(self.batch_size, self.num_bits), dtype=tf.float32)\n",
    "        )\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: self._generator(indices),\n",
    "            output_signature=output_signature\n",
    "        )\n",
    "        \n",
    "        # Aggressive prefetching for GPU utilization\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "# Create dataset loader - data will be loaded into RAM\n",
    "print(\"=\"*70)\n",
    "data_loader = PUSCHDataset(dataset_path, batch_size=16, validation_split=0.1)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Neural Receiver Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=(3, 3), activation='relu'):\n",
    "    \"\"\"ResNet-style residual block\"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    # First conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    \n",
    "    # Second conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Match dimensions if needed\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, (1, 1), padding='same')(shortcut)\n",
    "    \n",
    "    # Add residual\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation(activation)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def attention_block(x, key_dim=64):\n",
    "    \"\"\"Multi-head self-attention for focusing on reliable subcarriers\"\"\"\n",
    "    # Get spatial dimensions from shape (batch dimension handled automatically)\n",
    "    height, width, channels = x.shape[1:]\n",
    "    \n",
    "    # Flatten spatial dimensions: [batch, seq_len, features]\n",
    "    x_reshaped = layers.Reshape((height * width, channels))(x)\n",
    "    \n",
    "    # Multi-head attention\n",
    "    attn_output = layers.MultiHeadAttention(\n",
    "        num_heads=4,\n",
    "        key_dim=key_dim,\n",
    "        dropout=0.1\n",
    "    )(x_reshaped, x_reshaped)\n",
    "    \n",
    "    # Reshape back to spatial dimensions\n",
    "    attn_output = layers.Reshape((height, width, channels))(attn_output)\n",
    "    \n",
    "    # Residual connection\n",
    "    x = layers.Add()([x, attn_output])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_neural_receiver(input_shape, num_bits, num_rx_antennas=4):\n",
    "    \"\"\"Build neural receiver model\n",
    "    \n",
    "    Args:\n",
    "        input_shape: (num_rx, num_subcarriers, num_symbols, 2)\n",
    "        num_bits: Number of output bits\n",
    "        num_rx_antennas: Number of receive antennas\n",
    "    \n",
    "    Returns:\n",
    "        Keras model\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=input_shape, name='received_signal')\n",
    "    \n",
    "    # Spatial processing: process each RX antenna separately then combine\n",
    "    antenna_features = []\n",
    "    for rx_idx in range(num_rx_antennas):\n",
    "        # Extract single antenna: [batch, num_sc, num_sym, 2]\n",
    "        x = layers.Lambda(lambda x, idx=rx_idx: x[:, idx, :, :, :])(inputs)\n",
    "        \n",
    "        # Initial feature extraction\n",
    "        x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        antenna_features.append(x)\n",
    "    \n",
    "    # Combine antenna features\n",
    "    if num_rx_antennas > 1:\n",
    "        x = layers.Concatenate(axis=-1)(antenna_features)\n",
    "    else:\n",
    "        x = antenna_features[0]\n",
    "    \n",
    "    # Deep feature extraction with ResNet blocks\n",
    "    x = residual_block(x, filters=64, kernel_size=(5, 3))\n",
    "    x = residual_block(x, filters=64, kernel_size=(5, 3))\n",
    "    x = layers.MaxPooling2D((2, 1))(x)  # [896,14] -> [448,14]\n",
    "    \n",
    "    x = residual_block(x, filters=128, kernel_size=(5, 3))\n",
    "    x = residual_block(x, filters=128, kernel_size=(5, 3))\n",
    "    \n",
    "    # Moderate pooling before attention to fit in 48GB memory\n",
    "    # Reduces sequence length from 6272 to 1568 (4x reduction)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)  # [448,14] -> [224,7]\n",
    "    \n",
    "    # Attention mechanism (seq_len=1568, fits comfortably in 48GB)\n",
    "    x = attention_block(x, key_dim=64)\n",
    "    \n",
    "    x = residual_block(x, filters=256, kernel_size=(3, 3))\n",
    "    x = layers.MaxPooling2D((2, 1))(x)  # [224,7] -> [112,7]\n",
    "    \n",
    "    x = residual_block(x, filters=256, kernel_size=(3, 3))\n",
    "    \n",
    "    # Global feature aggregation\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layers for LLR estimation\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Output: LLRs (log-likelihood ratios)\n",
    "    # Use tanh activation to bound outputs\n",
    "    outputs = layers.Dense(num_bits, activation='tanh', name='llr_output')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='neural_receiver')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_neural_receiver(\n",
    "    input_shape=(*data_loader.input_shape, 2),\n",
    "    num_bits=data_loader.num_bits,\n",
    "    num_rx_antennas=num_rx_antennas\n",
    ")\n",
    "\n",
    "print(\"\\nüß† Neural Receiver Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Count parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nüìä Total parameters: {total_params:,}\")\n",
    "print(f\"   Model size: ~{total_params * 4 / 1024**2:.1f} MB (FP32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Loss and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_with_llr(y_true, y_pred):\n",
    "    \"\"\"BCE loss for LLR outputs\n",
    "    \n",
    "    y_true: ground truth bits (0 or 1)\n",
    "    y_pred: predicted LLRs (tanh output, -1 to +1)\n",
    "    \"\"\"\n",
    "    # Convert bits {0, 1} to {-1, +1}\n",
    "    y_true_bipolar = 2.0 * y_true - 1.0\n",
    "    \n",
    "    # LLR-based BCE\n",
    "    # When bit=1 (bipolar=+1), we want LLR > 0\n",
    "    # When bit=0 (bipolar=-1), we want LLR < 0\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=(y_true_bipolar + 1.0) / 2.0,\n",
    "        logits=y_pred * 5.0  # Scale LLRs\n",
    "    )\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def bit_error_rate(y_true, y_pred):\n",
    "    \"\"\"Bit Error Rate metric\"\"\"\n",
    "    # Hard decision: LLR > 0 ‚Üí bit = 1\n",
    "    y_pred_hard = tf.cast(y_pred > 0, tf.float32)\n",
    "    \n",
    "    errors = tf.not_equal(y_true, y_pred_hard)\n",
    "    ber = tf.reduce_mean(tf.cast(errors, tf.float32))\n",
    "    \n",
    "    return ber\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=binary_cross_entropy_with_llr,\n",
    "    metrics=[bit_error_rate]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model compiled\")\n",
    "print(f\"   Optimizer: Adam (lr=1e-3)\")\n",
    "print(f\"   Loss: Binary Cross-Entropy with LLR\")\n",
    "print(f\"   Metrics: Bit Error Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "EPOCHS = 20\n",
    "INITIAL_LR = 1e-3\n",
    "MIN_LR = 1e-6\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    # Save BEST model (based on validation BER)\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '/opt/app-root/src/models/neural_rx_best.h5',\n",
    "        monitor='val_bit_error_rate',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Save checkpoint EVERY epoch (for crash recovery)\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '/opt/app-root/src/models/neural_rx_epoch_{epoch:02d}.h5',\n",
    "        save_freq='epoch',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=MIN_LR,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Early stopping\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_bit_error_rate',\n",
    "        mode='min',  # Lower BER is better\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=f'/opt/app-root/src/results/logs/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Training configuration:\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Initial LR: {INITIAL_LR}\")\n",
    "print(f\"   Checkpointing:\")\n",
    "print(f\"     - Best model: neural_rx_best.h5 (when val_ber improves)\")\n",
    "print(f\"     - Every epoch: neural_rx_epoch_XX.h5 (crash recovery)\")\n",
    "print(f\"   Callbacks: LR Scheduler, Early Stopping, TensorBoard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Neural Receiver\n",
    "\n",
    "‚è±Ô∏è **Expected Duration**: ~2 hours on RTX 4090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datasets\n",
    "train_dataset = data_loader.get_dataset(training=True)\n",
    "val_dataset = data_loader.get_dataset(training=False)\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = len(data_loader.train_indices) // data_loader.batch_size\n",
    "validation_steps = len(data_loader.val_indices) // data_loader.batch_size\n",
    "\n",
    "print(f\"\\nüöÄ Starting training...\")\n",
    "print(f\"   Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"   Validation steps: {validation_steps}\")\n",
    "print(f\"   Total epochs: {EPOCHS}\")\n",
    "print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "# Train\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ Training complete!\")\n",
    "print(f\"   Total time: {training_time/3600:.2f} hours\")\n",
    "print(f\"   Final BER: {history.history['val_bit_error_rate'][-1]:.6f}\")\n",
    "print(f\"   Best BER: {min(history.history['val_bit_error_rate']):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save('/opt/app-root/src/models/neural_rx_final.h5')\n",
    "print(f\"‚úÖ Final model saved: /opt/app-root/src/models/neural_rx_final.h5\")\n",
    "\n",
    "# Save model architecture as JSON\n",
    "with open('/opt/app-root/src/models/neural_rx_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "print(f\"‚úÖ Architecture saved: /opt/app-root/src/models/neural_rx_architecture.json\")\n",
    "\n",
    "# Save training history\n",
    "history_dict = {\n",
    "    'loss': history.history['loss'],\n",
    "    'val_loss': history.history['val_loss'],\n",
    "    'bit_error_rate': history.history['bit_error_rate'],\n",
    "    'val_bit_error_rate': history.history['val_bit_error_rate'],\n",
    "    'training_time_hours': training_time / 3600,\n",
    "    'epochs': len(history.history['loss'])\n",
    "}\n",
    "\n",
    "with open('/opt/app-root/src/results/training_history.json', 'w') as f:\n",
    "    json.dump(history_dict, f, indent=2)\n",
    "print(f\"‚úÖ Training history saved: /opt/app-root/src/results/training_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# BER curves\n",
    "axes[1].semilogy(history.history['bit_error_rate'], label='Training BER', linewidth=2)\n",
    "axes[1].semilogy(history.history['val_bit_error_rate'], label='Validation BER', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Bit Error Rate')\n",
    "axes[1].set_title('Training and Validation BER')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/opt/app-root/src/results/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Training curves saved: /opt/app-root/src/results/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quick Performance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference speed\n",
    "print(\"\\n‚ö° Testing inference performance...\\n\")\n",
    "\n",
    "# Load best model\n",
    "best_model = keras.models.load_model(\n",
    "    '/opt/app-root/src/models/neural_rx_best.h5',\n",
    "    custom_objects={\n",
    "        'binary_cross_entropy_with_llr': binary_cross_entropy_with_llr,\n",
    "        'bit_error_rate': bit_error_rate\n",
    "    }\n",
    ")\n",
    "\n",
    "# Get test batch\n",
    "test_batch = next(iter(val_dataset))\n",
    "x_test, y_test = test_batch\n",
    "\n",
    "# Warmup\n",
    "for _ in range(10):\n",
    "    _ = best_model.predict(x_test, verbose=0)\n",
    "\n",
    "# Benchmark\n",
    "num_runs = 100\n",
    "latencies = []\n",
    "\n",
    "for _ in tqdm(range(num_runs), desc=\"Benchmarking\"):\n",
    "    start = time.time()\n",
    "    _ = best_model.predict(x_test, verbose=0)\n",
    "    latencies.append(time.time() - start)\n",
    "\n",
    "latencies = np.array(latencies)\n",
    "\n",
    "print(f\"\\nüìä Inference Performance (FP32):\")\n",
    "print(f\"   Batch size: {data_loader.batch_size}\")\n",
    "print(f\"   Mean latency: {latencies.mean() * 1000:.2f} ms\")\n",
    "print(f\"   Std latency: {latencies.std() * 1000:.2f} ms\")\n",
    "print(f\"   Throughput: {data_loader.batch_size / latencies.mean():.1f} slots/sec\")\n",
    "print(f\"   Per-slot latency: {latencies.mean() * 1000 / data_loader.batch_size:.3f} ms\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Note: TensorRT optimization (next notebook) will reduce latency to <1ms per slot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**‚úÖ Neural receiver training complete!**\n",
    "\n",
    "**Models saved:**\n",
    "- Best model: `/opt/app-root/src/models/neural_rx_best.h5`\n",
    "- Final model: `/opt/app-root/src/models/neural_rx_final.h5`\n",
    "- Architecture: `/opt/app-root/src/models/neural_rx_architecture.json`\n",
    "\n",
    "**Results:**\n",
    "- Training history: `/opt/app-root/src/results/training_history.json`\n",
    "- Training curves: `/opt/app-root/src/results/training_curves.png`\n",
    "\n",
    "**Next Steps:**\n",
    "1. Proceed to `03-optimize-tensorrt.ipynb` for FP16 optimization\n",
    "2. Target: <1ms inference latency per slot\n",
    "3. Then validate performance in `04-validate-performance.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
