{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRT Optimization for Neural Receiver\n",
    "\n",
    "**Objective**: Convert TensorFlow model to TensorRT for optimized inference\n",
    "\n",
    "**Expected Speedup**: 5-10x faster than native TensorFlow\n",
    "\n",
    "**Target Latency**: <1ms per PUSCH slot\n",
    "\n",
    "**Runtime**: ~10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Optimization Pipeline\n",
    "\n",
    "```\n",
    "TensorFlow Model (.h5)\n",
    "       ‚Üì\n",
    "SavedModel Format\n",
    "       ‚Üì\n",
    "TF-TRT Conversion (FP16)\n",
    "       ‚Üì\n",
    "Optimized Model\n",
    "       ‚Üì\n",
    "Calibration & Validation\n",
    "```\n",
    "\n",
    "## TensorRT Optimizations\n",
    "\n",
    "1. **Precision**: FP32 ‚Üí FP16 (2x speedup, minimal accuracy loss)\n",
    "2. **Layer fusion**: Combine Conv+BN+ReLU into single kernels\n",
    "3. **Kernel auto-tuning**: Select fastest CUDA kernels for RTX 4090\n",
    "4. **Memory optimization**: Reduce memory bandwidth requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"TensorRT integration: {'Available' if hasattr(trt, 'TrtGraphConverterV2') else 'Not available'}\")\n",
    "\n",
    "# Configure GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"‚úÖ GPU configured: {gpus}\")\n",
    "\n",
    "# Check CUDA compute capability\n",
    "from tensorflow.python.platform import build_info\n",
    "print(f\"\\nCUDA version: {build_info.build_info.get('cuda_version', 'N/A')}\")\n",
    "print(f\"cuDNN version: {build_info.build_info.get('cudnn_version', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss and metrics (needed for loading)\n",
    "def binary_cross_entropy_with_llr(y_true, y_pred):\n",
    "    \"\"\"BCE loss for LLR outputs\"\"\"\n",
    "    y_true_bipolar = 2.0 * y_true - 1.0\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=(y_true_bipolar + 1.0) / 2.0,\n",
    "        logits=y_pred * 5.0\n",
    "    )\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def bit_error_rate(y_true, y_pred):\n",
    "    \"\"\"Bit Error Rate metric\"\"\"\n",
    "    y_pred_hard = tf.cast(y_pred > 0, tf.float32)\n",
    "    errors = tf.not_equal(y_true, y_pred_hard)\n",
    "    return tf.reduce_mean(tf.cast(errors, tf.float32))\n",
    "\n",
    "# Load best model from training\n",
    "model_path = '/opt/app-root/src/models/neural_rx_best.h5'\n",
    "\n",
    "print(f\"üìÇ Loading model: {model_path}\")\n",
    "print(f\"   File size: {os.path.getsize(model_path) / 1024**2:.1f} MB\\n\")\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    model_path,\n",
    "    custom_objects={\n",
    "        'binary_cross_entropy_with_llr': binary_cross_entropy_with_llr,\n",
    "        'bit_error_rate': bit_error_rate\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully\")\n",
    "print(f\"   Input shape: {model.input_shape}\")\n",
    "print(f\"   Output shape: {model.output_shape}\")\n",
    "print(f\"   Parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Benchmark Native TensorFlow Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "dataset_path = '/opt/app-root/src/data/pusch_dataset.h5'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "with h5py.File(dataset_path, 'r') as f:\n",
    "    # Load a test batch\n",
    "    y_test = f['y_received'][0:BATCH_SIZE]\n",
    "    bits_test = f['bits'][0:BATCH_SIZE]\n",
    "    \n",
    "    # Convert complex to real [batch, rx, sc, sym, 2]\n",
    "    y_test_real = np.stack([y_test.real, y_test.imag], axis=-1).astype(np.float32)\n",
    "    bits_test = bits_test.reshape(bits_test.shape[0], -1).astype(np.float32)\n",
    "\n",
    "print(f\"üìä Test batch loaded:\")\n",
    "print(f\"   Input shape: {y_test_real.shape}\")\n",
    "print(f\"   Output shape: {bits_test.shape}\")\n",
    "\n",
    "# Warmup\n",
    "print(f\"\\nüî• Warming up TensorFlow model...\")\n",
    "for _ in range(50):\n",
    "    _ = model.predict(y_test_real, verbose=0)\n",
    "\n",
    "# Benchmark\n",
    "print(f\"‚ö° Benchmarking TensorFlow (FP32)...\")\n",
    "num_runs = 200\n",
    "tf_latencies = []\n",
    "\n",
    "for _ in tqdm(range(num_runs), desc=\"TF Inference\"):\n",
    "    start = time.time()\n",
    "    predictions = model.predict(y_test_real, verbose=0)\n",
    "    tf_latencies.append(time.time() - start)\n",
    "\n",
    "tf_latencies = np.array(tf_latencies)\n",
    "\n",
    "print(f\"\\nüìä TensorFlow Baseline Performance:\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Mean latency: {tf_latencies.mean() * 1000:.2f} ms\")\n",
    "print(f\"   Std latency: {tf_latencies.std() * 1000:.2f} ms\")\n",
    "print(f\"   Per-slot latency: {tf_latencies.mean() * 1000 / BATCH_SIZE:.3f} ms\")\n",
    "print(f\"   Throughput: {BATCH_SIZE / tf_latencies.mean():.1f} slots/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert to SavedModel Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as SavedModel (required for TensorRT conversion)\n",
    "savedmodel_path = '/opt/app-root/src/models/neural_rx_savedmodel'\n",
    "\n",
    "print(f\"üíæ Saving model in SavedModel format...\")\n",
    "model.save(savedmodel_path, save_format='tf')\n",
    "print(f\"‚úÖ SavedModel created: {savedmodel_path}\")\n",
    "\n",
    "# Verify SavedModel\n",
    "loaded_model = tf.saved_model.load(savedmodel_path)\n",
    "infer = loaded_model.signatures['serving_default']\n",
    "\n",
    "print(f\"\\nüìã SavedModel signature:\")\n",
    "print(f\"   Inputs: {list(infer.structured_input_signature[1].keys())}\")\n",
    "print(f\"   Outputs: {list(infer.structured_outputs.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert to TensorRT (FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorRT conversion parameters\n",
    "trt_savedmodel_path = '/opt/app-root/src/models/neural_rx_trt_fp16'\n",
    "\n",
    "print(f\"\\nüöÄ Converting to TensorRT (FP16)...\")\n",
    "print(f\"   This may take 5-10 minutes for kernel optimization\\n\")\n",
    "\n",
    "# Create TensorRT converter\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "    precision_mode=trt.TrtPrecisionMode.FP16,\n",
    "    max_workspace_size_bytes=8 * (1 << 30),  # 8 GB\n",
    "    minimum_segment_size=3,\n",
    "    use_calibration=False\n",
    ")\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=savedmodel_path,\n",
    "    conversion_params=conversion_params\n",
    ")\n",
    "\n",
    "print(f\"‚öôÔ∏è  Conversion parameters:\")\n",
    "print(f\"   Precision: FP16\")\n",
    "print(f\"   Max workspace: 8 GB\")\n",
    "print(f\"   Minimum segment size: 3\")\n",
    "print(f\"\\nüîß Building TensorRT engines (this takes time)...\\n\")\n",
    "\n",
    "# Convert\n",
    "start_time = time.time()\n",
    "converter.convert()\n",
    "\n",
    "# Build engines (kernel auto-tuning happens here)\n",
    "def input_fn():\n",
    "    \"\"\"Provide sample inputs for engine building\"\"\"\n",
    "    yield (tf.constant(y_test_real, dtype=tf.float32),)\n",
    "\n",
    "converter.build(input_fn=input_fn)\n",
    "\n",
    "# Save optimized model\n",
    "converter.save(trt_savedmodel_path)\n",
    "conversion_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ TensorRT conversion complete!\")\n",
    "print(f\"   Time: {conversion_time:.1f} seconds\")\n",
    "print(f\"   Saved to: {trt_savedmodel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Benchmark TensorRT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorRT model\n",
    "print(f\"\\nüìÇ Loading TensorRT model...\")\n",
    "trt_model = tf.saved_model.load(trt_savedmodel_path)\n",
    "trt_infer = trt_model.signatures['serving_default']\n",
    "\n",
    "# Get input tensor name\n",
    "input_tensor_name = list(trt_infer.structured_input_signature[1].keys())[0]\n",
    "output_tensor_name = list(trt_infer.structured_outputs.keys())[0]\n",
    "\n",
    "print(f\"‚úÖ TensorRT model loaded\")\n",
    "print(f\"   Input tensor: {input_tensor_name}\")\n",
    "print(f\"   Output tensor: {output_tensor_name}\")\n",
    "\n",
    "# Warmup\n",
    "print(f\"\\nüî• Warming up TensorRT model...\")\n",
    "for _ in range(100):\n",
    "    _ = trt_infer(**{input_tensor_name: tf.constant(y_test_real, dtype=tf.float32)})\n",
    "\n",
    "# Benchmark\n",
    "print(f\"‚ö° Benchmarking TensorRT (FP16)...\")\n",
    "trt_latencies = []\n",
    "\n",
    "for _ in tqdm(range(num_runs), desc=\"TRT Inference\"):\n",
    "    start = time.time()\n",
    "    predictions = trt_infer(**{input_tensor_name: tf.constant(y_test_real, dtype=tf.float32)})\n",
    "    trt_latencies.append(time.time() - start)\n",
    "\n",
    "trt_latencies = np.array(trt_latencies)\n",
    "\n",
    "print(f\"\\nüìä TensorRT Performance:\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Mean latency: {trt_latencies.mean() * 1000:.2f} ms\")\n",
    "print(f\"   Std latency: {trt_latencies.std() * 1000:.2f} ms\")\n",
    "print(f\"   Per-slot latency: {trt_latencies.mean() * 1000 / BATCH_SIZE:.3f} ms\")\n",
    "print(f\"   Throughput: {BATCH_SIZE / trt_latencies.mean():.1f} slots/sec\")\n",
    "\n",
    "# Calculate speedup\n",
    "speedup = tf_latencies.mean() / trt_latencies.mean()\n",
    "print(f\"\\nüöÄ Speedup: {speedup:.2f}x faster than TensorFlow FP32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate Numerical Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare TensorFlow vs TensorRT predictions\n",
    "print(f\"\\nüîç Validating numerical accuracy...\\n\")\n",
    "\n",
    "# Get predictions from both models\n",
    "tf_pred = model.predict(y_test_real, verbose=0)\n",
    "trt_pred = trt_infer(**{input_tensor_name: tf.constant(y_test_real, dtype=tf.float32)})\n",
    "trt_pred = trt_pred[output_tensor_name].numpy()\n",
    "\n",
    "# Calculate differences\n",
    "abs_diff = np.abs(tf_pred - trt_pred)\n",
    "rel_diff = abs_diff / (np.abs(tf_pred) + 1e-7)\n",
    "\n",
    "print(f\"üìä Numerical Comparison:\")\n",
    "print(f\"   Mean absolute difference: {abs_diff.mean():.6f}\")\n",
    "print(f\"   Max absolute difference: {abs_diff.max():.6f}\")\n",
    "print(f\"   Mean relative difference: {rel_diff.mean() * 100:.4f}%\")\n",
    "print(f\"   Max relative difference: {rel_diff.max() * 100:.4f}%\")\n",
    "\n",
    "# Hard decision comparison (most important for communications)\n",
    "tf_bits = (tf_pred > 0).astype(np.float32)\n",
    "trt_bits = (trt_pred > 0).astype(np.float32)\n",
    "bit_agreement = (tf_bits == trt_bits).mean()\n",
    "\n",
    "print(f\"\\nüéØ Hard Decision Agreement: {bit_agreement * 100:.2f}%\")\n",
    "\n",
    "# Calculate BER on test batch\n",
    "tf_ber = (tf_bits != bits_test).mean()\n",
    "trt_ber = (trt_bits != bits_test).mean()\n",
    "\n",
    "print(f\"\\nüìâ Bit Error Rate:\")\n",
    "print(f\"   TensorFlow FP32: {tf_ber:.6f}\")\n",
    "print(f\"   TensorRT FP16: {trt_ber:.6f}\")\n",
    "print(f\"   Difference: {abs(tf_ber - trt_ber):.6f}\")\n",
    "\n",
    "if bit_agreement > 0.99:\n",
    "    print(f\"\\n‚úÖ Numerical accuracy is excellent! (>99% agreement)\")\n",
    "elif bit_agreement > 0.95:\n",
    "    print(f\"\\n‚ö†Ô∏è  Numerical accuracy is acceptable (>95% agreement)\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Warning: Low numerical accuracy (<95% agreement)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize LLR Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LLR distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Scatter plot\n",
    "sample_indices = np.random.choice(tf_pred.size, size=min(10000, tf_pred.size), replace=False)\n",
    "axes[0, 0].scatter(tf_pred.flatten()[sample_indices], \n",
    "                   trt_pred.flatten()[sample_indices], \n",
    "                   alpha=0.1, s=1)\n",
    "axes[0, 0].plot([-1, 1], [-1, 1], 'r--', linewidth=2, label='y=x')\n",
    "axes[0, 0].set_xlabel('TensorFlow LLR')\n",
    "axes[0, 0].set_ylabel('TensorRT LLR')\n",
    "axes[0, 0].set_title('LLR Correlation')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of differences\n",
    "axes[0, 1].hist(abs_diff.flatten(), bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Absolute Difference')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Distribution of LLR Differences')\n",
    "axes[0, 1].set_yscale('log')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Hard decision comparison\n",
    "confusion = np.zeros((2, 2))\n",
    "for tf_b, trt_b in zip(tf_bits.flatten(), trt_bits.flatten()):\n",
    "    confusion[int(tf_b), int(trt_b)] += 1\n",
    "\n",
    "im = axes[1, 0].imshow(confusion, cmap='Blues')\n",
    "axes[1, 0].set_xlabel('TensorRT Decision')\n",
    "axes[1, 0].set_ylabel('TensorFlow Decision')\n",
    "axes[1, 0].set_title('Hard Decision Confusion Matrix')\n",
    "axes[1, 0].set_xticks([0, 1])\n",
    "axes[1, 0].set_yticks([0, 1])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = axes[1, 0].text(j, i, f'{int(confusion[i, j])}',\n",
    "                              ha=\"center\", va=\"center\", color=\"black\", fontsize=14)\n",
    "plt.colorbar(im, ax=axes[1, 0])\n",
    "\n",
    "# Latency comparison\n",
    "latency_data = [\n",
    "    tf_latencies * 1000 / BATCH_SIZE,\n",
    "    trt_latencies * 1000 / BATCH_SIZE\n",
    "]\n",
    "axes[1, 1].boxplot(latency_data, labels=['TensorFlow\\nFP32', 'TensorRT\\nFP16'])\n",
    "axes[1, 1].set_ylabel('Latency per slot (ms)')\n",
    "axes[1, 1].set_title(f'Inference Latency (Speedup: {speedup:.2f}x)')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 1].axhline(y=1.0, color='r', linestyle='--', linewidth=2, label='1ms target')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/opt/app-root/src/results/tensorrt_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Comparison plot saved: /opt/app-root/src/results/tensorrt_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimization results\n",
    "optimization_metrics = {\n",
    "    'tensorflow': {\n",
    "        'precision': 'FP32',\n",
    "        'mean_latency_ms': float(tf_latencies.mean() * 1000),\n",
    "        'std_latency_ms': float(tf_latencies.std() * 1000),\n",
    "        'per_slot_latency_ms': float(tf_latencies.mean() * 1000 / BATCH_SIZE),\n",
    "        'throughput_slots_per_sec': float(BATCH_SIZE / tf_latencies.mean()),\n",
    "        'ber': float(tf_ber)\n",
    "    },\n",
    "    'tensorrt': {\n",
    "        'precision': 'FP16',\n",
    "        'mean_latency_ms': float(trt_latencies.mean() * 1000),\n",
    "        'std_latency_ms': float(trt_latencies.std() * 1000),\n",
    "        'per_slot_latency_ms': float(trt_latencies.mean() * 1000 / BATCH_SIZE),\n",
    "        'throughput_slots_per_sec': float(BATCH_SIZE / trt_latencies.mean()),\n",
    "        'ber': float(trt_ber)\n",
    "    },\n",
    "    'speedup': float(speedup),\n",
    "    'numerical_accuracy': {\n",
    "        'mean_abs_diff': float(abs_diff.mean()),\n",
    "        'max_abs_diff': float(abs_diff.max()),\n",
    "        'mean_rel_diff_percent': float(rel_diff.mean() * 100),\n",
    "        'hard_decision_agreement_percent': float(bit_agreement * 100)\n",
    "    },\n",
    "    'hardware': {\n",
    "        'gpu': 'NVIDIA GeForce RTX 4090 D',\n",
    "        'batch_size': BATCH_SIZE\n",
    "    },\n",
    "    'conversion_time_seconds': conversion_time\n",
    "}\n",
    "\n",
    "with open('/opt/app-root/src/results/tensorrt_optimization.json', 'w') as f:\n",
    "    json.dump(optimization_metrics, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Optimization metrics saved: /opt/app-root/src/results/tensorrt_optimization.json\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üìä OPTIMIZATION SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüöÄ Performance Gain:\")\n",
    "print(f\"   Speedup: {speedup:.2f}x\")\n",
    "print(f\"   TF FP32: {tf_latencies.mean() * 1000 / BATCH_SIZE:.3f} ms/slot\")\n",
    "print(f\"   TRT FP16: {trt_latencies.mean() * 1000 / BATCH_SIZE:.3f} ms/slot\")\n",
    "print(f\"\\nüéØ Accuracy:\")\n",
    "print(f\"   Hard decision agreement: {bit_agreement * 100:.2f}%\")\n",
    "print(f\"   BER difference: {abs(tf_ber - trt_ber):.6f}\")\n",
    "print(f\"\\nüíæ Models:\")\n",
    "print(f\"   TensorFlow: {model_path}\")\n",
    "print(f\"   TensorRT: {trt_savedmodel_path}\")\n",
    "print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**‚úÖ TensorRT optimization complete!**\n",
    "\n",
    "**Models created:**\n",
    "- TensorFlow SavedModel: `/opt/app-root/src/models/neural_rx_savedmodel/`\n",
    "- TensorRT FP16: `/opt/app-root/src/models/neural_rx_trt_fp16/`\n",
    "\n",
    "**Results:**\n",
    "- Optimization metrics: `/opt/app-root/src/results/tensorrt_optimization.json`\n",
    "- Comparison plots: `/opt/app-root/src/results/tensorrt_comparison.png`\n",
    "\n",
    "**Key Achievements:**\n",
    "- Significant speedup through FP16 precision and kernel optimization\n",
    "- Minimal accuracy loss (>99% hard decision agreement)\n",
    "- Production-ready inference latency\n",
    "\n",
    "**Next Steps:**\n",
    "1. Proceed to `04-validate-performance.ipynb`\n",
    "2. Measure BLER across SNR range\n",
    "3. Compare against conventional receiver\n",
    "4. Generate final performance plots for Telco-AIX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
